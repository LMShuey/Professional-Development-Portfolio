AI Safety and Red Teaming - Project Work Flowchart quick reference

AI Lab (Model Developer)
   ↓
Defines safety risks & goals
   ↓
Issues Statement of Work (SOW)
   ↓
Contractor (Third-party vendor)
   ↓
Recruits & trains Remote Workers
   ↓
Assigns Batch / Queue (100–1,000 tasks)
   ↓
Remote Worker (Red Teamer / Safety Evaluator)
   ↓
Receives Task / Goal
   ↓
Crafts Adversarial Prompt(s)
   ↓
Submits to Model
   ↓
Observes Output
   ↓
Writes Evaluation Report / Write-up
   ↓
Submits Report
   ↓
Contractor Audits (random / targeted QC)
   ↓
High Agreement? ──► Yes ──► Approved → More / Priority tasks
   ↓ No
Repeated failures? ──► Yes ──► Rate-limited → Fewer tasks / Lower pay
   ↓ Yes
Consistent low quality? ──► Yes ──► Removed from project
   ↓
Contractor Aggregates findings
   ↓
Delivers compiled report to AI Lab
   ↓
AI Lab Reviews results
   ↓
Implements fixes / updates
   ↓
Deploys improved model